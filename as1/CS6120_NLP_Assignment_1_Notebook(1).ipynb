{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bc97d6da",
      "metadata": {
        "id": "bc97d6da"
      },
      "source": [
        "## CS 6120: Natural Language Processing - Prof. Ahmad Uzair\n",
        "\n",
        "### Assignment 1: Naive Bayes\n",
        "### Total Points: 100 points\n",
        "\n",
        "You will be dealing with movie review data that includes both positive and negative reviews in this assignment. You will use Sentiment Analysis to assess if a given review is positive or negative using the provided dataset.\n",
        "\n",
        "Therefore, we will make use of Naive Bayes algorithm to perform sentiment analysis on the movie review dataset.\n",
        "\n",
        "## Importing the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "a03450ac",
      "metadata": {
        "id": "a03450ac"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# additional lib\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc584cc2",
      "metadata": {
        "id": "fc584cc2"
      },
      "source": [
        "## Reading the data\n",
        "\n",
        "When reading the data, ensure that the '.csv' file is in the same location where your jupyter notebook is used. This way the files are organized and easy to read using the pandas library. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3c9ffbf5",
      "metadata": {
        "id": "3c9ffbf5"
      },
      "outputs": [],
      "source": [
        "## Reading the data and removing columns that are not important. \n",
        "df = pd.read_csv(\"movie_reviews.csv\", sep = ',', encoding = 'latin-1', usecols = lambda col: col not in [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f7fa8ac0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "f7fa8ac0",
        "outputId": "69edaf28-1e2e-4ec7-9530-b30a2853ab9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bound method NDFrame.head of                                                   review sentiment\n",
            "0      One of the other reviewers has mentioned that ...  positive\n",
            "1      A wonderful little production. <br /><br />The...  positive\n",
            "2      I thought this was a wonderful way to spend ti...  positive\n",
            "3      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "4      Probably my all-time favorite movie, a story o...  positive\n",
            "...                                                  ...       ...\n",
            "24694  I have seen this movie at the cinema many year...  negative\n",
            "24695  This movie was a real torture fest to sit thro...  negative\n",
            "24696  John Wayne & Albert Dekker compete for oil rig...  negative\n",
            "24697  Tarantino once remarked on a melodrama from th...  positive\n",
            "24698  Aah yes the workout show was a great. Not only...  positive\n",
            "\n",
            "[24699 rows x 2 columns]>\n"
          ]
        }
      ],
      "source": [
        "print(df.head) # print head of data frame with help of head function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1749da04",
      "metadata": {
        "id": "1749da04"
      },
      "source": [
        "## Count plot of the output categories: positive or negative\n",
        "\n",
        "Feel free to take a look at the output and whether the classes are balanced or imbalanced. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c152e8a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "c152e8a4",
        "outputId": "a2ba0476-3238-4511-fcf0-780508493f48"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# set the figure size\n",
        "plt.figure(figsize = (8, 6), dpi = 100)\n",
        "sns.countplot(x = 'sentiment', data = df)\n",
        "plt.title(\"Positive Vs. Negative reviews count\", fontsize = 15)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b8549f2",
      "metadata": {
        "id": "9b8549f2"
      },
      "source": [
        "## Upsampling the minority class: (5 points)\n",
        "\n",
        "It is known that Naive bayes is not robust to class imbalance. It could be seen above that the data is little imbalanced. Therefore, class balancing can be done before giving it to the Naive Bayes model for prediction. \n",
        "\n",
        "Feel free to use 'resample' library from sklearn. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "yHJTAqrW7XMN",
      "metadata": {
        "id": "yHJTAqrW7XMN"
      },
      "outputs": [],
      "source": [
        "## hint: use resample from sklearn.utils\n",
        "from sklearn.utils import resample\n",
        "\n",
        "df_majority = df[df.sentiment == 'positive']\n",
        "df_minority = df[df.sentiment == 'negative']\n",
        "\n",
        "negative_upsample = resample(df_minority, \n",
        "                             replace = True, \n",
        "                             n_samples = df_majority.shape[0],\n",
        "                             random_state = 101)\n",
        "\n",
        "df_upsampled = pd.concat([df_majority, negative_upsample])  # concat two data frames i,e majority class data set and upsampled minority class data set\n",
        "df_upsampled = df_upsampled.sample(frac = 1, random_state = 101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6a9329bb",
      "metadata": {
        "id": "6a9329bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12474, 2)\n"
          ]
        }
      ],
      "source": [
        "## Just to ensure that upsampling was done successfully, take a look at the shape of the data in \n",
        "## this cell. \n",
        "\n",
        "# print the shape of data set with the help of shape function having \"negative\" as class label\n",
        "df_negative_upsampled = df_upsampled[df_upsampled.sentiment == 'negative']\n",
        "print(df_negative_upsampled.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f8bf6e7",
      "metadata": {
        "id": "6f8bf6e7"
      },
      "source": [
        "### Expected Output : \n",
        "(12474, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bdea8155",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdea8155",
        "outputId": "c665c4b9-826e-4f4e-e30e-06e0935a0622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12474, 2)\n"
          ]
        }
      ],
      "source": [
        "## Ensure that the same number of data points are present for both 'positive' and 'negative' data\n",
        "\n",
        "# print the shape of data set with the help of shape function having \"positive\" as class label\n",
        "df_positive_upsampled = df_upsampled[df_upsampled.sentiment == 'positive']\n",
        "print(df_positive_upsampled.shape) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "626f01d5",
      "metadata": {
        "id": "626f01d5"
      },
      "source": [
        "### Expected Output : \n",
        "(12474, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "NoW5z6SzAeP8",
      "metadata": {
        "id": "NoW5z6SzAeP8"
      },
      "outputs": [],
      "source": [
        "## In this cell, we are going to be dividing the data into train and test points\n",
        "## Ensure that you store the upsampled data in a variable called 'df_upsampled' \n",
        "## so that the below operations are performed successfully\n",
        "\n",
        "input_feature_col = 'review'\n",
        "target_col = 'sentiment'\n",
        "\n",
        "## Considering 10000 positive and 10000 negative data points\n",
        "negative_data_points_train = df_upsampled[df_upsampled[target_col] == 'negative'].iloc[:10000]\n",
        "positive_data_points_train = df_upsampled[df_upsampled[target_col] == 'positive'].iloc[:10000]\n",
        "\n",
        "## Considering the remaining data points for test\n",
        "negative_data_points_test = df_upsampled[df_upsampled[target_col] == 'negative'].iloc[10000:]\n",
        "positive_data_points_test = df_upsampled[df_upsampled[target_col] == 'positive'].iloc[10000:]\n",
        "\n",
        "## Concatenate the training positive and negative reviews\n",
        "X_train = pd.concat([negative_data_points_train[input_feature_col], \n",
        "                     positive_data_points_train[input_feature_col]])\n",
        "## Concatenating the training positive and negative outputs\n",
        "y_train = pd.concat([negative_data_points_train[target_col], \n",
        "                     positive_data_points_train[target_col]])\n",
        "\n",
        "## Concatenating the test positive and negative reviews\n",
        "X_test = pd.concat([negative_data_points_test[input_feature_col], \n",
        "                    positive_data_points_test[input_feature_col]])\n",
        "## Concatenating the test positive and negative outputs\n",
        "y_test = pd.concat([negative_data_points_test[target_col], \n",
        "                    positive_data_points_test[target_col]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6428047d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6428047d",
        "outputId": "10d10601-0ce0-4688-c4d3-75fa386583fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "negative    10000\n",
            "positive    10000\n",
            "Name: sentiment, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "## Take a look at the total number of classes and their count using '.value_counts()' for y_train and y_test.\n",
        "## Ensure that there are equal number of positive and negative reviews. \n",
        "\n",
        "# Class distribution in y_train\n",
        "print(y_train.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dfe6517",
      "metadata": {
        "id": "7dfe6517"
      },
      "source": [
        "### Expected Output:\n",
        "negative    10000<br>\n",
        "positive    10000<br>\n",
        "Name: sentiment, dtype: int64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2beae1d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2beae1d6",
        "outputId": "6896f930-6a1a-45db-b74c-d080c9aedd0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "negative    2474\n",
            "positive    2474\n",
            "Name: sentiment, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Class distribution in y_test:\n",
        "\n",
        "print(y_test.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9163f897",
      "metadata": {
        "id": "9163f897"
      },
      "source": [
        "### Expected Output : \n",
        "negative    2474<br>\n",
        "positive    2474<br>\n",
        "Name: sentiment, dtype: int64"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6501699b",
      "metadata": {
        "id": "6501699b"
      },
      "source": [
        "## Q1. Pre-process the reviews: (10 points)\n",
        "\n",
        "We know that a review contains links, punctuation, stopwords and many other words that don't give a lot of meaning for the Naive Bayes model for prediction. \n",
        "\n",
        "In the cell below, one must implement text-preprocessing and remove links, punctuations and stopwords. It is also important to lowercase the letters so that 'Admire' and 'admire' are not treated as different words. \n",
        "\n",
        "In addition to this, perform stemming operation so that similar words are reduced. To know more about stemming, feel free to take a look at this link.\n",
        "\n",
        "https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "CirLN9-ddQ1r",
      "metadata": {
        "id": "CirLN9-ddQ1r"
      },
      "outputs": [],
      "source": [
        "# TASK CELL\n",
        "\n",
        "def clean_review(review):\n",
        "    '''\n",
        "    Input:\n",
        "        review: a string containing a review.\n",
        "    Output:\n",
        "        review_cleaned: a processed review. \n",
        "\n",
        "    '''\n",
        "    # Remove links\n",
        "    review = re.sub(r'http\\S+', '', review)\n",
        "    \n",
        "    # Remove punctuations\n",
        "    review = review.translate(str.maketrans('', '', string.punctuation))\n",
        "    \n",
        "    # Remove stopwords\n",
        "    review_words = review.split()\n",
        "    filtered_words = [word for word in review_words if word not in stopwords.words('english')]\n",
        "    \n",
        "    # Switch to lowercase \n",
        "    review = review.lower()\n",
        "    \n",
        "    # Perform stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    words_stemmed = [stemmer.stem(word) for word in filtered_words]\n",
        "    review_cleaned = \" \".join(words_stemmed)\n",
        "    \n",
        "    \n",
        "    '''\n",
        "    Since we need to use perform stemming, \n",
        "    but if we use this operate, \n",
        "    then the word will be optimize to the minimalist form, \n",
        "    then the “movie -> movi” is correct. \n",
        "    But it's seems like not same as the \"Expected output\", \n",
        "    I search online, we can try use WordNetLemmatizer to instead of stemming. \n",
        "    But I'm not sure its valid for statement or not.\n",
        "    Content: \n",
        "    Manjot Bedi 3 hours ago\n",
        "    It's fine even if the output is different. \n",
        "    It won't affect the frequency count for individual words.\n",
        "    Since I use stemming, base the instruction statement.  \n",
        "    \n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
        "    \n",
        "    review_cleaned = ' '.join(lemmatized_words)\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    return review_cleaned"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7632fe5",
      "metadata": {
        "id": "a7632fe5"
      },
      "source": [
        "## Q2. Implement a find_occurrence function (5 points):\n",
        "\n",
        "In this function, we find the total occurrence of a word giving information such as label, word and frequency dictionary.\n",
        "\n",
        "Note that this function is used later in the code when we are going to be predicting the output using Naive Bayes. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "eb282b81",
      "metadata": {
        "id": "eb282b81"
      },
      "outputs": [],
      "source": [
        "# TASK CELL\n",
        "def find_occurrence(frequency, word, label):\n",
        "    '''\n",
        "    Params:\n",
        "        frequency: a dictionary with the frequency of each pair (or tuple)\n",
        "        word: the word to look up\n",
        "        label: the label corresponding to the word\n",
        "    Return:\n",
        "        n: the number of times the word with its corresponding label appears.\n",
        "    '''\n",
        "    \n",
        "    n = frequency.get((word, label), 0)\n",
        "    \n",
        "    return n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29a2249d",
      "metadata": {
        "id": "29a2249d"
      },
      "source": [
        "### Converting output to numerical format:\n",
        "\n",
        "We have outputs as 'positive' or 'negative'. In the cell below, we convert it to a numerical format. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "bcdc2b2c",
      "metadata": {
        "id": "bcdc2b2c"
      },
      "outputs": [],
      "source": [
        "## With the use of mapping function, we replace\n",
        "## the label in the form of string to an integer. \n",
        "\n",
        "output_map = {'positive': 0, 'negative': 1}\n",
        "y_train = y_train.map(output_map)\n",
        "y_test = y_test.map(output_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "3dde0bbd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dde0bbd",
        "outputId": "223dfbc1-8efe-4183-b6d7-c9cb025cb285"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    10000\n",
              "0    10000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Ensuring that there are equal number of classes on the training data. \n",
        "y_train.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f2959b85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "f2959b85",
        "outputId": "e514214b-cd57-43fc-875d-1821ddab63f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"So this ugly guy with long, nasty hair and his girlfriend end up in this house and they argue and argue about his old girlfriend. There was suppose to be something scary in it but I didn't see anything scary at all. There is some mention of a demon from the sea but that doesn't go anywhere at all. I wish it did because then it would've taken the tension away from the jealous love triangle. The title of the movie makes it look like it would be a scary and exciting movie but it is so far from it that I couldn't believe it. I waited and waited for it to end and was so happy when it did. It did not live up to the title like it should have so boo hoo hoo. The cover had a cool picture but I shouldn't judge a cheesy movie by its cover.\""
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Choosing a random review and taking a look at it.\n",
        "X_train.iloc[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed5e43c9",
      "metadata": {
        "id": "ed5e43c9"
      },
      "source": [
        "From the above cell output, it could be seen that there are a lot of words that don't add a lot of meaning to the text. \n",
        "\n",
        "Therefore, those words would be removed. It also reduces the computation time. \n",
        "\n",
        "Therefore, it is a good practice we are following."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "e0498520",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download() # Active nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ad3937ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad3937ea",
        "outputId": "68985efe-32cd-4c11-ed5b-2e1e1b297e73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "so ugli guy long nasti hair girlfriend end hous argu argu old girlfriend there suppos someth scari i didnt see anyth scari there mention demon sea doesnt go anywher i wish wouldv taken tension away jealou love triangl the titl movi make look like would scari excit movi far i couldnt believ i wait wait end happi it live titl like boo hoo hoo the cover cool pictur i shouldnt judg cheesi movi cover\n"
          ]
        }
      ],
      "source": [
        "custom_review = X_train.iloc[0]\n",
        "\n",
        "# print cleaned review\n",
        "print(clean_review(custom_review))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e6cc440",
      "metadata": {
        "id": "3e6cc440"
      },
      "source": [
        "We now use this function to pre-process the review and remove words that don't add a lot of meaning in our model. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a762960",
      "metadata": {
        "id": "5a762960"
      },
      "source": [
        "## Q3. Implementing review counter function: (5 points)\n",
        "\n",
        "It is now time to implement the count function for the reviews. \n",
        "\n",
        "In this function, we count the occurrence of words and get the probabilities \n",
        "for the words based on the training data. \n",
        "\n",
        "In other words, we get the probability of occurrence of a word, given that the output is 'positive'.\n",
        "\n",
        "Similarly, we also compute the probability of occurence of a word, given that the output is 'negative'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "5de61f77",
      "metadata": {
        "id": "5de61f77"
      },
      "outputs": [],
      "source": [
        "# TASK CELL\n",
        "def review_counter(output_occurrence, reviews, positive_or_negative):\n",
        "    '''\n",
        "    Params:\n",
        "        output_occurrence: a dictionary that will be used to map each pair to its frequency\n",
        "        reviews: a list of reviews\n",
        "        positive_or_negative: a list corresponding to the sentiment of each review (either 0 or 1)\n",
        "    Return:\n",
        "        output: a dictionary mapping each pair to its frequency\n",
        "    '''\n",
        "    ## Steps :\n",
        "    # define the key, which is the word and label tuple\n",
        "    # if the key exists in the dictionary, increment the count\n",
        "    # else, if the key is new, add it to the dictionary and set the count to 1\n",
        "    \n",
        "    for label, review in zip(positive_or_negative, reviews):\n",
        "      split_review = clean_review(review).split()\n",
        "      for word in split_review:\n",
        "        # --- Your code here ---\n",
        "        \n",
        "        # define the key, which is the word and label tuple\n",
        "            key = (word, label)\n",
        "            \n",
        "            # if the key exists in the dictionary, increment the count\n",
        "            if key in output_occurrence:\n",
        "                output_occurrence[key] += 1\n",
        "            # else, if the key is new, add it to the dictionary and set the count to 1\n",
        "            else:\n",
        "                output_occurrence[key] = 1\n",
        "        # --- Code End ---\n",
        "        \n",
        "    return output_occurrence\n",
        "   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18238223",
      "metadata": {
        "id": "18238223"
      },
      "source": [
        "### Test your function with example reviews:\n",
        "\n",
        "Feel free to run the cell below and understand whether the above function that you have defined is producing the optimum results. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "07a4c58a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07a4c58a",
        "outputId": "dd9e148a-34a9-4cfe-9077-c5de33493d7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{('got', 1): 1,\n",
              " ('bore', 1): 2,\n",
              " ('throught', 1): 1,\n",
              " ('moview', 1): 1,\n",
              " ('the', 0): 1,\n",
              " ('movi', 0): 2,\n",
              " ('fantast', 0): 1,\n",
              " ('will', 1): 1,\n",
              " ('watch', 1): 1,\n",
              " ('wa', 1): 1,\n",
              " ('complet', 1): 1,\n",
              " ('wast', 1): 1,\n",
              " ('time', 1): 1,\n",
              " ('money', 1): 1,\n",
              " ('enjoy', 0): 1,\n",
              " ('fullest', 0): 1}"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Testing your function\n",
        "\n",
        "result = {}\n",
        "reviews = ['got bored throught the moview', 'The movie was fantastic', 'Will not watch it again', 'Was bored, it was a complete waste of time and money', 'Enjoyed the movie to the fullest']\n",
        "ys = [1, 0, 1, 1, 0]\n",
        "review_counter(result, reviews, ys)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ab975e1",
      "metadata": {},
      "source": [
        "# Expect Output Analysis: \n",
        "Since we need to use perform stemming, \n",
        "    but if we use this operate, \n",
        "    then the word will be optimize to the minimalist form, \n",
        "    then the “movie -> movi” is correct. \n",
        "    But it's seems like not same as the \"Expected output\", \n",
        "    I search online, we can try use WordNetLemmatizer to instead of stemming. \n",
        "    But I'm not sure its valid for statement or not.\n",
        "    Content: \n",
        "    Manjot Bedi 3 hours ago\n",
        "    It's fine even if the output is different. \n",
        "    It won't affect the frequency count for individual words.\n",
        "    Since I use stemming, base the instruction statement.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "927f89bb",
      "metadata": {
        "id": "927f89bb"
      },
      "source": [
        "### Expected Output:\n",
        " {('bored', 1): 2, <br>\n",
        " ('complete', 1): 1, <br>\n",
        " ('enjoyed', 0): 1, <br>\n",
        " ('fantastic', 0): 1, <br>\n",
        " ('fullest', 0): 1, <br>\n",
        " ('got', 1): 1, <br>\n",
        " ('money', 1): 1, <br>\n",
        " ('movie', 0): 2, <br>\n",
        " ('moview', 1): 1, <br>\n",
        " ('throught', 1): 1, <br>\n",
        " ('time', 1): 1, <br>\n",
        " ('waste', 1): 1, <br>\n",
        " ('watch', 1): 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "9bc62e13",
      "metadata": {
        "id": "9bc62e13"
      },
      "outputs": [],
      "source": [
        "# Build the freqs dictionary for later uses\n",
        "\n",
        "freqs = review_counter({}, X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "0eddf420",
      "metadata": {
        "id": "0eddf420"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('so', 1) 1184\n",
            "('ugli', 1) 229\n",
            "('guy', 1) 2134\n",
            "('long', 1) 1295\n",
            "('nasti', 1) 167\n",
            "('hair', 1) 235\n",
            "('girlfriend', 1) 241\n",
            "('end', 1) 3596\n",
            "('hous', 1) 768\n",
            "('argu', 1) 105\n"
          ]
        }
      ],
      "source": [
        "## Run this cell to get an idea about the corpus of words and their occurrence along with labels. \n",
        "## In this, we are computing the frequency of occurrence of word given that a review is 'positive'.\n",
        "## Similarly, we also compute the frequence of occurence of word given that a review is 'negative'.\n",
        "\n",
        "# print(freqs)\n",
        "for key, value in list(freqs.items())[:10]:\n",
        "    print(key, value)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "759c24bc",
      "metadata": {
        "id": "759c24bc"
      },
      "source": [
        "## Q4. Training the Naive Bayes Model: (20 points)\n",
        "\n",
        "Now we are in the training phase of the Naive Bayes algorithm. In this cell, take a look at the ways to calculate the log likelihood and log prior values as these are important for testing in the next few cells. \n",
        "\n",
        "Also calculate the frequency of occurrence of words where the output is negative. In the same way, calculate the word frequency count using the above functions in order to compute the log likelihood.\n",
        "\n",
        "Return the logprior and loglikelihood output by the model from this function. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "a7f280e3",
      "metadata": {
        "id": "a7f280e3"
      },
      "outputs": [],
      "source": [
        "def train_naive_bayes(freqs, train_x, train_y):\n",
        "    '''\n",
        "    Input:\n",
        "        freqs: dictionary from (word, label) to how often the word appears\n",
        "        train_x: a list of reviews\n",
        "        train_y: a list of labels correponding to the reviews (0,1)\n",
        "    Output:\n",
        "        logprior: the log prior. (equation 3 above)\n",
        "        loglikelihood: the log likelihood of you Naive bayes equation. (equation 6 above)\n",
        "    '''\n",
        "    loglikelihood = {}\n",
        "    logprior = 0\n",
        "\n",
        "\n",
        "    # calculate V, the number of unique words in the vocabulary\n",
        "    vocab = set([pair[0] for pair in freqs.keys()])\n",
        "    V = len(vocab)\n",
        "\n",
        "    # calculate num_pos and num_neg - the total number of positive and negative words for all documents\n",
        "    num_pos = num_neg = 0\n",
        "    for pair in freqs.keys():\n",
        "        # if the label is positive (greater than zero)\n",
        "        if pair[1] == 1:\n",
        "\n",
        "            # Increment the number of positive words by the count for this (word, label) pair\n",
        "            num_pos += freqs[pair]\n",
        "\n",
        "        # else, the label is negative\n",
        "        else:\n",
        "\n",
        "            # increment the number of negative words by the count for this (word,label) pair\n",
        "            num_neg += freqs[pair]\n",
        "\n",
        "    # Calculate num_doc, the number of documents\n",
        "    num_doc = len(train_x)\n",
        "\n",
        "    # Calculate D_pos, the number of positive documents \n",
        "    pos_num_docs = sum(1 for label in train_y if label == 1)\n",
        "\n",
        "    # Calculate D_neg, the number of negative documents \n",
        "    neg_num_docs = num_doc - pos_num_docs\n",
        "\n",
        "    # Calculate logprior\n",
        "    logprior = math.log(pos_num_docs) - math.log(neg_num_docs)\n",
        "\n",
        "    # For each word in the vocabulary...\n",
        "    for word in vocab:\n",
        "        # get the positive and negative frequency of the word\n",
        "        freq_pos = freqs.get((word, 1), 0)\n",
        "        freq_neg = freqs.get((word, 0), 0)\n",
        "\n",
        "        # calculate the probability that each word is positive, and negative\n",
        "        p_w_pos = (freq_pos + 1) / (num_pos + V)\n",
        "        p_w_neg = (freq_neg + 1) / (num_neg + V)\n",
        "\n",
        "        # calculate the log likelihood of the word\n",
        "        loglikelihood[word] = math.log(p_w_pos/p_w_neg)\n",
        "\n",
        "\n",
        "    return logprior, loglikelihood"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "1561d892",
      "metadata": {
        "id": "1561d892"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n",
            "75453\n"
          ]
        }
      ],
      "source": [
        "# You do not have to input any code in this cell, but it is relevant to grading, so please do not change anything\n",
        "logprior, loglikelihood = train_naive_bayes(freqs, X_train, y_train)\n",
        "print(logprior)\n",
        "print(len(loglikelihood))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "980a7f45",
      "metadata": {},
      "source": [
        "# Output Analysis：\n",
        "Since the model and function of data_clean different, it should be show different Loglikelihood value. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19d9c882",
      "metadata": {
        "id": "19d9c882"
      },
      "source": [
        "### Expected Output \n",
        "\n",
        "0.0 <br>\n",
        "91425"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78b51303",
      "metadata": {
        "id": "78b51303"
      },
      "source": [
        "## Q5. Implementing Naive Bayes Predict Function: (10 points)\n",
        "\n",
        "It is now time to make our prediction as to whether a given review is negative or positive respectively. \n",
        "\n",
        "After adding the log likelihood values, ensure that the output is 1 (negative) if the sum of the log likelihood value is greater than 0 and 0 (positive) if the sum of the log likelihood is less than or equal to 0. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "b692c2f9",
      "metadata": {
        "id": "b692c2f9"
      },
      "outputs": [],
      "source": [
        "# TASK 4 CELL\n",
        "\n",
        "def naive_bayes_predict(review, logprior, loglikelihood):\n",
        "    '''\n",
        "    Params:\n",
        "        review: a string\n",
        "        logprior: a number\n",
        "        loglikelihood: a dictionary of words mapping to numbers\n",
        "    Return:\n",
        "        total_prob: the sum of all the loglikelihoods of each word in the review (if found in the dictionary) + logprior (a number)\n",
        "\n",
        "    '''\n",
        "    \n",
        "      # process the review to get a list of words\n",
        "    word_l = clean_review(review).split()\n",
        "\n",
        "    # initialize probability to zero\n",
        "    total_prob = 0\n",
        "\n",
        "    # add the logprior\n",
        "    total_prob = logprior\n",
        "\n",
        "    for word in word_l:\n",
        "\n",
        "        # check if the word exists in the loglikelihood dictionary\n",
        "        if word in loglikelihood:\n",
        "            # add the log likelihood of that word to the probability\n",
        "            total_prob += loglikelihood[word]\n",
        "\n",
        "\n",
        "    return 1 if total_prob > 0 else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "4b170333",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b170333",
        "outputId": "0cf6bc90-90e8-4dee-bf95-7eaf39dce147"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The expected output is 1\n"
          ]
        }
      ],
      "source": [
        "# You do not have to input any code in this cell, but it is relevant to grading, so please do not change anything\n",
        "\n",
        "# Experiment with your own review.\n",
        "my_review = \"I thought this series was going to be another fun, action series with some dynamic plots and great performances. I was wrong. While I like Jamie Denton, this show is hardly worth watching at all, unless you enjoy watching some people brutalized and the actions of the agents supposedly warranted under the theme of national security. The show is great propaganda for the current government, and spews out jingoism as though we talk that way every day. After a couple of episodes, it was boring the hell out of me, and I started watching reruns of House Invaders on BBCAmerica instead. Rather watch CSI and Without a Trace, without a doubt.\"\n",
        "p = naive_bayes_predict(my_review, logprior, loglikelihood)\n",
        "print('The expected output is', p)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6242708f",
      "metadata": {
        "id": "6242708f"
      },
      "source": [
        "### Expected Output :\n",
        "The expected output is 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c4eeb71",
      "metadata": {
        "id": "7c4eeb71"
      },
      "source": [
        "## Q6. Implementing Naive Bayes Test function: (10 points)\n",
        "\n",
        "In this function, implement the previous functions such as naive_bayes_predict to get the predictions for the test set. \n",
        "\n",
        "In addition to this, the function should return the total number of reviews that it correctly classified as 'positive' or 'negative'. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "66a511e7",
      "metadata": {
        "id": "66a511e7"
      },
      "outputs": [],
      "source": [
        "# UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "def test_naive_bayes(test_x, test_y, logprior, loglikelihood):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        test_x: A list of reviews\n",
        "        test_y: the corresponding labels for the list of reviews\n",
        "        logprior: the logprior\n",
        "        loglikelihood: a dictionary with the loglikelihoods for each word\n",
        "    Output:\n",
        "        accuracy: (# of reviews classified correctly)/(total # of reviews)\n",
        "    \"\"\"\n",
        "    accuracy = 0  \n",
        "\n",
        "    \n",
        "    y_hats = []\n",
        "    for review in test_x:\n",
        "        \n",
        "        # Predict the sentiment of the review\n",
        "        total_prob = naive_bayes_predict(review, logprior, loglikelihood)\n",
        "        \n",
        "        # if the prediction is > 0\n",
        "        if total_prob > 0:\n",
        "            # the predicted class is 1\n",
        "            y_hat_i = 1\n",
        "        else:\n",
        "            # otherwise the predicted class is 0\n",
        "            y_hat_i = 0\n",
        "\n",
        "        # append the predicted class to the list y_hats\n",
        "        y_hats.append(y_hat_i)\n",
        "\n",
        "    # error is the average of the absolute values of the differences between y_hats and test_y\n",
        "    error = [abs(y_hat - y) for y_hat, y in zip(y_hats, test_y)]\n",
        "\n",
        "    accuracy = sum(error) / len(test_y)\n",
        "\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "8a9c5d9d",
      "metadata": {
        "id": "8a9c5d9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "If you like original gut wrenching laughter you will like this movie. If you are young or old then y -> 0.00\n",
            "What a waste of talent. A very poor, semi-coherent, script cripples this film. Rather unimaginative  -> 1.00\n",
            "I have seen this film at least 100 times and I am still excited by it, the acting is perfect and the -> 0.00\n",
            "Cheap, amateurish, unimaginative, exploitative... but don't think it'll have redeeming amusement val -> 1.00\n"
          ]
        }
      ],
      "source": [
        "# For grading purpose only\n",
        "# You do not have to input any code in this cell, but it is relevant to grading, so please do not change anything\n",
        "\n",
        "# Run this cell to test your function\n",
        "\n",
        "for review in [\"If you like original gut wrenching laughter you will like this movie. If you are young or old then you will love this movie, hell even my mom liked it.<br /><br />Great Camp!!!\",\n",
        "                \"What a waste of talent. A very poor, semi-coherent, script cripples this film. Rather unimaginative direction, too. Some VERY faint echoes of Fargo here, but it just doesn't come off.\",\n",
        "                \"I have seen this film at least 100 times and I am still excited by it, the acting is perfect and the romance between Joe and Jean keeps me on the edge of my seat, plus I still think Bryan Brown is the tops. Brilliant Film.\",\n",
        "                \"Cheap, amateurish, unimaginative, exploitative... but don't think it'll have redeeming amusement value. About as unentertaining, uninstructive and just plain dull as a film can be.\"]:\n",
        "    p = naive_bayes_predict(review, logprior, loglikelihood)\n",
        "    print(f'{review[:100]} -> {p:.2f}')\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43e2ef98",
      "metadata": {
        "id": "43e2ef98"
      },
      "source": [
        "### Expected Output :\n",
        "\n",
        "If you like original gut wrenching laughter you will like this movie. If you are young or old then y -> 0.00 <br>\n",
        "What a waste of talent. A very poor, semi-coherent, script cripples this film. Rather unimaginative  -> 1.00<br>\n",
        "I have seen this film at least 100 times and I am still excited by it, the acting is perfect and the -> 0.00 <br>\n",
        "Cheap, amateurish, unimaginative, exploitative... but don't think it'll have redeeming amusement val -> 1.00\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "216fa97a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "216fa97a",
        "outputId": "9d1f21c7-b324-43c2-e841-269c0306cbb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Feel free to check the sentiment of your own review below\n",
        "my_review = 'The moview was very boring, I wanted to leave in the middle'\n",
        "naive_bayes_predict(my_review, logprior, loglikelihood)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a45e4f0",
      "metadata": {
        "id": "8a45e4f0"
      },
      "source": [
        "### Expected Output :\n",
        "1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mAIkM4aCC1H7",
      "metadata": {
        "id": "mAIkM4aCC1H7"
      },
      "source": [
        "# Q7. Evaluate the accuracy (10 Points)\n",
        "1. Split your data into training and test sets using random selection. Set the seed as parameter of the function so that user can select a different training and test set by changin seed.\n",
        "\n",
        "2. Calculate model paramters with training set.\n",
        "\n",
        "3. Print confusion matrix for training and test set.\n",
        "\n",
        "4. Examine False Positive and False Negative cases and provide reasoning why they get misclassified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "6a8f8467",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def naive_bayes(X, y, freqs, seed=42, test_size=0.2): \n",
        "\n",
        "    def split_data(X, y, test_size = 0.2, seed = None):\n",
        "        return train_test_split(X, y, test_size = test_size, random_state = seed)\n",
        "\n",
        "    # 1. Split the data into training and test sets\n",
        "    X_train, X_test, y_train, y_test = split_data(X, y, test_size=0.2, seed=42)\n",
        "\n",
        "    # 2. Calculate model parameters with training set\n",
        "    logprior, loglikelihood = train_naive_bayes(freqs, X_train, y_train)\n",
        "\n",
        "    def predict_reviews(reviews, logprior, loglikelihood):\n",
        "        return [1 if naive_bayes_predict(review, logprior, loglikelihood) > 0 else 0 for review in reviews]\n",
        "\n",
        "    # Predictions for training and test sets\n",
        "    y_train_pred = predict_reviews(X_train, logprior, loglikelihood)\n",
        "    y_test_pred = predict_reviews(X_test, logprior, loglikelihood)\n",
        "\n",
        "    # 3. Print confusion matrix\n",
        "    print(\"Training Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_train, y_train_pred))\n",
        "    print(\"\\nTest Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_test_pred))\n",
        "\n",
        "    # 4. Examine False Positives and False Negatives\n",
        "    # Get the index of false positives and false negatives\n",
        "    false_positives = [i for i, \n",
        "                       (true, pred) in enumerate(zip(y_test, y_test_pred)) \n",
        "                       if true == 1 and pred == 0] # 这是误报为正面的负面评论\n",
        "    false_negatives = [i for i, \n",
        "                       (true, pred) in enumerate(zip(y_test, y_test_pred)) \n",
        "                       if true == 0 and pred == 1] # 这是误报为负面的正面评论\n",
        "\n",
        "    # Print some misclassified samples\n",
        "    print(\"Some False Positives:\")\n",
        "    for i in false_positives[:5]:  # Print the first 5 false positives\n",
        "        print(X_test[i])\n",
        "\n",
        "    print(\"\\nSome False Negatives:\")\n",
        "    for i in false_negatives[:5]:  # Print the first 5 false negatives\n",
        "        print(X_test[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "50bfe444",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model_params saved for Q8\n",
        "import pickle \n",
        "def save_model_params(logprior, loglikelihood, filename = 'model_params.pkl'):\n",
        "    with open(filename, 'wb') as file:\n",
        "        pickle.dump((logprior, loglikelihood), file)\n",
        "\n",
        "save_model_params(logprior, loglikelihood)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "f2ca23af",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Confusion Matrix:\n",
            "[[8902 1101]\n",
            " [ 621 9135]]\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[2208  263]\n",
            " [ 146 2323]]\n",
            "Some False Positives:\n",
            "This video guide was the masterpiece of the year 1995. Beautifully done! Matthew Perry and Jennifer Aniston have major on-screen chemistry when they talk about what the Start button does. I'm waiting for Microsoft to release a Special Edition DVD complete with deleted scenes, Bill Gates commentary, a documentary of how Windows 95 compares to Windows XP, and more!<br /><br />Overall: 10/10 (Should have won at least a Golden Globe)\n",
            "This is an art film that was either made in 1969 or 1972 (the National Film Preservation Foundation says 1969 and IMDb says 1972). Regardless of the exact date, the film definitely appears to be very indicative of this general time period--with some camera-work and pop art stylings that are pure late 60s-early 70s.<br /><br />The film consists of three simple images that are distorted using different weird camera tricks. These distorted images are accompanied by music and there is absolutely no dialog or plot of any sort. This was obviously intended as almost like a form of performance art, and like most performance art, it's interesting at first but quickly becomes tiresome. The film, to put it even more bluntly, is a total bore and would appeal to no one but perhaps those who made the film, their family and friends and perhaps a few people just too hip and \"with it\" to be understood by us mortals.\n",
            "George & Mildred - The Movie lacks the talents of its TV writer John Mortimer who brings the close quarter cut and thrust of George's class war with the Fourmiles alive.<br /><br />The plot is cut from standard spin-off cloth - hit-man/mistaken identity - and has as little tension as there are laughs. The producers should have taken a leaf from Rising Damp, (also 1980)which was also bought to the big screen after the TV series demise, and kept much of the story in familiar setting.<br /><br />Yootha Joyce died in 1980 but she should not be remembered for this creaking piece of work encumbered as she was by her illness. Mildred lacks the sharpness of her TV incarnation; cutting asides and withering looks largely directed at Georges lack of libido. George's sputtering incredulity also gets lost in the more expansive sets. This is not to say that they were much to shout about. The budget for this movies looks pathetically small; a restaurant they go to is clearly a new semi-starched house with some Christmas lights adorning the front door.<br /><br />For fans of 70's British comedy or those who just want to revisit an old TV companion from their youth this film can add nothing to the experience and they should just stick to the first four TV series out now on DVD.\n",
            "Just in time to capitalize on the long-awaited movie version of \"Dreamgirls\" is the DVD release of this semi-forgotten 1976 musical melodrama that also takes the rise of the Supremes as its inspiration. Released five years before the Broadway opening of \"Dreamgirls\" and partially set in the same period, it has a predominantly black cast and a story revolving around an up-and-coming girl group, and that's where the resemblance basically ends. Written by Joel Schumacher well before he became a big-league director of mainstream studio product (\"Batman Forever\", \"The Phantom of the Opera\"), this movie seems grittier on the surface. True to form, however, Schumacher weakens the storyline and character development by injecting an abundance of clichÃ©s and eye-rolling one-liners. With little affinity for staging musical numbers, Sam O'Steen, a highly regarded film editor but neophyte director, helms the production like a low-budget TV-movie with a frustratingly episodic structure.<br /><br />The story follows three Harlem sisters - sexy Sister, self-righteous Delores and sweet Sparkle - as they sing in the church choir, meet smooth-talking but well-intentioned boys Stix and Levi, and then find their first taste of success as a singing group - first as a sweater-wearing quintet called the Hearts and then as a glitzy trio known as Sister and the Sisters. But naturally there are problems beyond the silly name for the group - Sister gets involved with nasty drug dealer Satin Struthers who beats her and turns her into a cocaine junkie; Levi goes to prison for getting caught in a drug pick-up for Satin; Stix gets frustrated by failure and unwisely turns to some Jewish mobsters for financial help; Delores just gets plain fed up; and poor little Sparkle has to decide what kind of future she wants. A big plus is that R&B great Curtis Mayfield wrote the atmospheric songs, some catchy and one, \"Look Into Your Heart\", a real winner.<br /><br />The solid cast does its best under the contrived circumstances. Lonette McKee's valiant attempt to make Sister a tragic figure is undercut by some of the ham-fisted plot turns, including a sad Billie Holliday-like turn at the mike. Before they hit it big on primetime TV, Philip Michael Thomas and Dorian Harewood portray Stix and Levi with boyish vitality if not much credibility. The best work comes from Mary Alice in a relatively silent turn as the girls' patient mother and a pre-\"Fame\" Irene Cara who effortlessly exudes sincerity in the title role (though her costumer and hair stylist should be shot for the hideous look she achieves in the final scene). The DVD just comes with the original theatrical trailer complete with an unctuous voice-over by DJ Casey Kasem and a bonus CD of five of the film's songs performed not by the original cast but by Aretha Franklin off her 1976 recording of the soundtrack. It's not a terrible movie, just an interesting if lacking curio that happens to cover the same ground as \"Dreamgirls\".\n",
            "this film has it all; the deft camera work, reminiscent of martin scorcese, or oliver stone, the tight acting of 'heat', the explosive action of a jerry bruckheimer movie, the witty dialogue of a tarantino script and the epic feel of say, 'the godfather'<br /><br />the judge reinhold character displays a fiery temperememt, yet also shows real emotional depth and intensity. his performance reminds me of robert de niro's portrayal of jake la motta in raging bull.<br /><br />the action scenes are truly breathtaking, not since bullit has a movie depicted such high octane, yet stylish car scenes. The special effects push the boundries of technology and filmmaking to their limits. Independance day set the standard that this movie clearly has matched, and greatly surpassed.<br /><br />overall, great acting from its a list cast (like an oscars night party invitation list!), classy locations, gripping action, and a tight script.\n",
            "\n",
            "Some False Negatives:\n",
            "Everyone knows about this ''Zero Day'' event. What I think this movie did that Elephant did not is that they made us see how these guys were. They showed their life for about a year. Throughout the movie we get to like them, to laugh with them even though we totally know what they're gonna do. And THAT gives me the chills. Cause I felt guilty to be cheered by their comments, and I just thought Cal was a sweet guy. Even though I KNEW what was gonna happen you know? Even at the end of the movie when they were about to commit suicide and just deciding if they did it on the count of 3 or 4 I thought this was funny but still I was horrified to see their heads blown off. Of course I was. I got to like them. They were wicked, maybe, but I felt like they were really normal guys, that they didn't really realize it. But I knew they were.<br /><br />That's, IMO, the main force of this movie. It makes us realize that our friends, or relatives, or anyone, can be planning something crazy, and that we won't even notice it. This movie, as good as it was, made me feel bad. And that's why I can't go to sleep right now. There's still this little feeling in my stomach. Butterflies.\n",
            "Of life in (some) colleges. Of course there were artistic licenses taken, but some of what you saw in this film go on in some colleges.<br /><br />I went to colleges in Southern California where the races pretty much hang around with their own. It's funny because these are schools that want racial unity, equality etc. and I can honestly say, that it's there. But the thing is when class lets out, or when they're just hanging out waiting for class, they (students) seem to just hang around with people of their own race or ethnicity. Is that bad? Not really. Everyone needs a feeling of belonging. But like the school paper of one of the schools I attended once wrote about that, \"we should all try to hang around with students of other ethnicities and try to know them.\" Otherwise you're creating your own segregation.<br /><br />Racism certainly existed in one of those schools I attended. One time someone put leaflets around campus talking about the glories of the Aryan Race and had the symbols of some of those racist organizations. Fortunately, nothing happened like the incident in the movie where the young Caucasian man went off and started shooting at a multiculturalism gathering.<br /><br />I can only hope and pray that nothing like that ever will happen.<br /><br />So is \"Higher Learning\" overly dramatic? Exaggerated? Maybe. Is it way \"off mark?\" It depends on where you went to or go to school. The race thing where the ethnicities just hang around with their own DOES happen. Minus the Hollywood exaggerations, the race thing hit pretty close to home for me.\n",
            "And a made for TV movie too, this movie was good. the acting in it and the plot was just so great. this one of the only movies I've seen that I felt warped my mind because after seeing it I was afraid of Reaper coming to kill me through my computer screen. There were just a few minor things wrong with this movie, but it's very easily over looked.<br /><br />Antonio Sabbato Jr did an excellent role in this movie along with Janine Turner and Robert Wagner. this movie just has so much suspense and it made me wanting more because I never thought a low budget TV movie could be so powerful. After viewing this I read the novel this movie was based on (four times) and it too kicked was great. If you ever see this movie come on TV, I'd watch it. The effects in this movie were pretty well done, I honestly don't know what a live calcifying human would look like but with the way the FX team did this movie I was impressed and all it shows is that all these bad made for TV movies out there with low budgets shouldn't suck so bad.<br /><br />watch it. It's really good, no really, it is!\n",
            "I originally saw this several years ago while I was sitting on the couch and got stuck watching it on HBO. With the remote out of my reach I decided to go with it and was awaiting a miserable movie that I had been avoiding for a year. So it started off and I wasn't very optimistic about it, but after about ten minutes I found myself laughing. The complete opposite as I was expecting. The comedy was smart, the acting pretty good considering, the cast worked very well together, and the story (though slightly awkward and fake) was actually quite entertaining.<br /><br />Three convict brothers manage to escape their sentence and eventually go in search of their fortune. The movie is set in the 1930's. So along the way, they encounter a number of funny and interesting charatcers. All have a different story or achievement they are striving for. Really the majority of the movie may seem random. Some may say it was pointless and boring, but if you look for the smart comedy (and occasionally stupid) that is integrated into the movie, I'm sure you'll enjoy this one.<br /><br />I liked the performances given by George Clooney, John Turturro, and Tim Blake Nelson. All of them did very well in their roles, an they worked great together. But to finish this off, \"O Brother, Where Art Thou?\" is a smart, funny, and a movie adventure that I wouldn't let pass up.\n",
            "I cannot believe someone gave this movie a 1 rating!!! and it is only a 3. average... What is not to love about this film? It is original, it has lots of scare scenes that actually made me jump out of my seat, and it has some great special effects. The story is fresh, there is some nudity, and it is very campy. The killer was scary in his own demented way and the end is very unexpected. I must admit that I really love this film, one of Spain's best horror films ever. If you consider yourself a true horror fan you need to get out there and try to find this film. You will be pleasantly surprised to do so.\n"
          ]
        }
      ],
      "source": [
        "# Testing function\n",
        "\n",
        "result = {}\n",
        "reviews = df['review'].tolist()\n",
        "\n",
        "y = [0 if sentiment == 'positive' else 1 for sentiment in df['sentiment']]\n",
        "result = review_counter(result, reviews, y)\n",
        "# print('Review: \\n', result)\n",
        "\n",
        "\n",
        "naive_bayes(reviews, y, result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XbzttYVnBo7W",
      "metadata": {
        "id": "XbzttYVnBo7W"
      },
      "source": [
        "# Q8. Modularize your calssifier (10 points)\n",
        "1. Convert your code into a python module text_classifier.py\n",
        "\n",
        "2. The user should be able to launch the application on command prompt using python test_classifier.py command. The module will automatically load the model paramters from a local file of your choice and be ready to take the input from user on command prompt. The program will preprocess user input, tokenize and predict the class.\n",
        "\n",
        "3. Your module will take the input from user and output sentiment class in an indefinite loop. The output should printout the probabilities for each input token along with the final classification decision. Program will quit if user enters X.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82e6e4d1",
      "metadata": {
        "id": "82e6e4d1"
      },
      "source": [
        "# Q9. Theory Questions: (10 points)\n",
        "\n",
        "1. Why is Laplace Smoothing or Additive Smoothing required while executing Naive Bayes operations, especially for text classification? Show how not having additive smoothing leads to bad outcomes by using an example of training and the test set. (10 points)\n",
        "\n",
        "\n",
        "2. Why are logarithmic values computed instead of only probability values in the Naive Bayes algorithm? (5 points)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CS6120_NLP_Assignment_1_Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
