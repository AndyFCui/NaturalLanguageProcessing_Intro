{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS6120 NLP Fall 2023 Assignment 3\n",
    "\n",
    "## Implementing Skipgram and CBOW Algorithms\n",
    "\n",
    "### Background: \n",
    "Word embeddings are dense vector representations of words in a continuous vector space. Skipgram and CBOW are two primary algorithms introduced by Mikolov et al. in their 2013 papers that form the basis of the popular word2vec model. While both are used for generating word embeddings, they use different architectures and techniques.\n",
    "\n",
    "- Skipgram: Given a word, this model predicts the surrounding context words.\n",
    "- CBOW (Continuous Bag-of-Words): Given context words, this model predicts the target word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks:\n",
    "1. Data Collection:\n",
    "Download the text8 dataset, which is a cleaned version of the first 100MB of the English Wikipedia dump. It is available on several NLP data repositories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Download the dataset\n",
    "url = \"http://mattmahoney.net/dc/text8.zip\"\n",
    "response = requests.get(url, allow_redirects = True)\n",
    "\n",
    "with open('text8.zip', 'wb') as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans culottes of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organization of society it has also been taken up as a positive label by self defined anarchists the word anarchism is derived from the greek without archons ruler chief king anarchism as a political philosophy is the belief that rulers are unnecessary and should be abolished although there are differing interpretations of what this means anarchism also refers to related social movements that advocate the elimination of authoritarian institutions particularly the state the word anarchy as most anarchists use it does not imply chaos nihilism or anomie but rather a harmonious anti authoritarian society in place of what are regarded as authoritarian political structures and coercive economic instituti\n",
      "<class 'str'>\n",
      "The length of the `data` is 100000000\n"
     ]
    }
   ],
   "source": [
    "# Loading and preparing the text8 dataset\n",
    "with open('text8', 'r') as file:\n",
    "    data = file.read()\n",
    "    \n",
    "print(data[:1000])\n",
    "print(type(data))\n",
    "print('The length of the {} is {}' .format('`data`', len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Pre-processing:\n",
    "- Tokenize the dataset.\n",
    "- Remove stopwords and non-alphabetic tokens.\n",
    "- Build a vocabulary of the most frequent words (e.g., top 10,000 or 20,000 words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.tokenize import  word_tokenize\n",
    "import nltk\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "# add more packages\n",
    "from typing import Dict\n",
    "from typing import Set\n",
    "from typing import List\n",
    "import math\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from math import sqrt\n",
    "from itertools import chain\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "def clean_corpus(line: list[str]) -> list[str]:\n",
    "    '''\n",
    "    preprocess and clean a given line.\n",
    "\n",
    "    - line: The text line to be cleaned.\n",
    "    ---\n",
    "    - list: A list of preprocessed tokens from the line.\n",
    "    '''\n",
    "    tokens = word_tokenize(line)\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]  \n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10888361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['anarchism',\n",
       " 'originated',\n",
       " 'term',\n",
       " 'abuse',\n",
       " 'first',\n",
       " 'used',\n",
       " 'early',\n",
       " 'working',\n",
       " 'class',\n",
       " 'radicals']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing the data\n",
    "lines: list[list[str]] = []\n",
    "\n",
    "# Predefined list of stop words\n",
    "stop_words: set = set(stopwords.words('english'))\n",
    "\n",
    "# Tokenize the text documents and update the lists word_list and lines\n",
    "lines = clean_corpus(data)\n",
    "print(len(lines))\n",
    "lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'zero',\n",
       " 'nine',\n",
       " 'two',\n",
       " 'eight',\n",
       " 'five',\n",
       " 'three',\n",
       " 'four',\n",
       " 'six',\n",
       " 'seven',\n",
       " 'also',\n",
       " 'first',\n",
       " 'many',\n",
       " 'new',\n",
       " 'used',\n",
       " 'american',\n",
       " 'time',\n",
       " 'see',\n",
       " 'may',\n",
       " 'world']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a vocabulary of the most frequent words (e.g., top 10,000 or 20,000 words).\n",
    "word_counts = Counter(lines)\n",
    "top_freq_words = [word for word, count in word_counts.most_common(10000)]\n",
    "top_freq_words[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsampling\n",
    "\n",
    "# Flatten the nested list\n",
    "flattened_lines = lines\n",
    "\n",
    "t = 1e-5 # # Hyperparameters\n",
    "\n",
    "word_counts = Counter(flattened_lines)\n",
    "total_count = len(flattened_lines)\n",
    "frequencies = {word: count/total_count for word, count in word_counts.items()}\n",
    "\n",
    "\n",
    "def subsample_prob(word):\n",
    "    prob = max(0, 1 - sqrt(t / frequencies[word]))\n",
    "    return prob\n",
    "\n",
    "subsamped_lines = [word for word in flattened_lines if random.random() > subsample_prob(word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4129394\n"
     ]
    }
   ],
   "source": [
    "print(len(subsamped_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anarchism',\n",
       " 'originated',\n",
       " 'working',\n",
       " 'radicals',\n",
       " 'diggers',\n",
       " 'sans',\n",
       " 'culottes',\n",
       " 'used',\n",
       " 'pejorative',\n",
       " 'organization']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check subsample\n",
    "subsamped_lines[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implement CBOW:\n",
    "- Create the architecture for CBOW with an embedding layer and a linear layer.\n",
    "- Generate training samples. For each word in the dataset, use n surrounding words as context.\n",
    "- Train the model using a suitable optimizer and loss function.\n",
    "- Extract word embeddings for the vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBOW is Continuous Bag Of Words, another vision of Word2Vec\n",
    "- Reference: https://www.youtube.com/watch?v=ghu_5o42QGQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training samples. For each word in the dataset, use n surrounding words as context.\n",
    "def generate_context_pairs(corpus, window_size, vocab_set):\n",
    "    data = []\n",
    "\n",
    "    for i, word in enumerate(corpus):\n",
    "        if word not in vocab_set:\n",
    "            continue\n",
    "\n",
    "        # Initialize an empty context list for the current word\n",
    "        context = []\n",
    "\n",
    "        # Define the start and end indices for the context words\n",
    "        start_index = max(0, i - window_size)\n",
    "        end_index = min(len(corpus), i + window_size + 1)\n",
    "\n",
    "        # Loop over the surrounding words within the window\n",
    "        for j in range(start_index, end_index):\n",
    "            # Exclude the current word itself\n",
    "            if j != i and corpus[j] in vocab_set:\n",
    "                context.append(corpus[j])\n",
    "\n",
    "        target = word\n",
    "        data.append((context, target))\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair 1:\n",
      "Context: ['originated', 'working']\n",
      "Target: anarchism\n",
      "----------------------\n",
      "Pair 2:\n",
      "Context: ['anarchism', 'working']\n",
      "Target: originated\n",
      "----------------------\n",
      "Pair 3:\n",
      "Context: ['anarchism', 'originated']\n",
      "Target: working\n",
      "----------------------\n",
      "Pair 4:\n",
      "Context: ['organization']\n",
      "Target: used\n",
      "----------------------\n",
      "Pair 5:\n",
      "Context: ['used', 'positive', 'label']\n",
      "Target: organization\n",
      "----------------------\n",
      "Pair 6:\n",
      "Context: ['organization', 'label', 'anarchists']\n",
      "Target: positive\n",
      "----------------------\n",
      "Pair 7:\n",
      "Context: ['organization', 'positive', 'anarchists', 'anarchism']\n",
      "Target: label\n",
      "----------------------\n",
      "Pair 8:\n",
      "Context: ['positive', 'label', 'anarchism']\n",
      "Target: anarchists\n",
      "----------------------\n",
      "Pair 9:\n",
      "Context: ['label', 'anarchists', 'chief']\n",
      "Target: anarchism\n",
      "----------------------\n",
      "Pair 10:\n",
      "Context: ['anarchism', 'anarchism', 'belief']\n",
      "Target: chief\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "# check function of genreate\n",
    "context_pairs = generate_context_pairs(subsamped_lines[:30000], 2, top_freq_words)\n",
    "\n",
    "# print head 10\n",
    "for i, (context, target) in enumerate(context_pairs[:10]):\n",
    "    print(f\"Pair {i+1}:\")\n",
    "    print(\"Context:\", context)\n",
    "    print(\"Target:\", target)\n",
    "    print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the architecture for CBOW with an embedding layer and a linear layer.\n",
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.linear = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, context_words):\n",
    "        embedded_words = self.embeddings(context_words)\n",
    "        avg_embedded = embedded_words.mean(dim=1)  # Corrected dim to 1\n",
    "        logits = self.linear(avg_embedded)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for DataLoader\n",
    "class CBOWDataset(Dataset):\n",
    "    def __init__(self, data, word2idx, max_context_size):\n",
    "        self.data = data\n",
    "        self.word2idx = word2idx\n",
    "        self.max_context_size = max_context_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        context, target = self.data[idx]\n",
    "\n",
    "        # Use <NEU> to paaend the context\n",
    "        while len(context) < self.max_context_size:\n",
    "            context.append(\"<NEU>\")  # Use a special padding token. \n",
    "\n",
    "        context_indices = [self.word2idx[word] for word in context]\n",
    "        target_index = self.word2idx[target]\n",
    "\n",
    "        return torch.tensor(context_indices, dtype=torch.long), torch.tensor(target_index, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "embedding_dim = 100\n",
    "learning_rate = 0.01\n",
    "epochs = 50\n",
    "window_size = 2\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "# Preparing data\n",
    "vocab = set(top_freq_words)\n",
    "vocab.add(\"<NEU>\")\n",
    "word2idx = {word: i for i, word in enumerate(vocab)}\n",
    "idx2word = {i: word for word, i in word2idx.items()}\n",
    "\n",
    "# Preprocess data\n",
    "training_data = generate_context_pairs(subsamped_lines, window_size, vocab)\n",
    "max_context_size = max([len(context) for context, _ in training_data])\n",
    "\n",
    "train_dataset = CBOWDataset(training_data, word2idx, max_context_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Model, Optimizer, Loss Function\n",
    "model = CBOW(len(vocab), embedding_dim).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# List to store losses\n",
    "epoch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# check GPU is work\n",
    "# Train the model using a suitable optimizer and loss function.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 4715/4715 [00:45<00:00, 104.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 43587.26419830322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 4715/4715 [00:45<00:00, 104.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 43411.513706207275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 4715/4715 [00:44<00:00, 106.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 43299.356311798096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 4715/4715 [00:47<00:00, 98.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 43218.09453582764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 4715/4715 [00:44<00:00, 105.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 43153.09973907471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 4715/4715 [00:44<00:00, 105.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 43100.16862010956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 4715/4715 [00:44<00:00, 105.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 43056.86109638214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 4715/4715 [00:47<00:00, 99.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 43021.32743549347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4715/4715 [00:44<00:00, 105.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 42991.87158489227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 4715/4715 [00:45<00:00, 104.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 42967.28111743927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 4715/4715 [00:44<00:00, 105.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 42946.348985672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 4715/4715 [00:44<00:00, 106.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 42928.32592487335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 4715/4715 [00:44<00:00, 106.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 42912.61415100098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 4715/4715 [00:47<00:00, 99.15it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 42898.65506649017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 4715/4715 [00:44<00:00, 105.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 42886.14266586304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 4715/4715 [00:44<00:00, 106.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 42874.669649124146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 4715/4715 [00:47<00:00, 98.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 42864.21823310852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 4715/4715 [00:44<00:00, 106.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 42854.40821361542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 4715/4715 [00:44<00:00, 105.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 42845.256081581116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 4715/4715 [00:44<00:00, 105.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 42836.53004169464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 4715/4715 [00:44<00:00, 105.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Loss: 42828.30844783783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 4715/4715 [00:44<00:00, 105.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Loss: 42820.36380767822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 4715/4715 [00:47<00:00, 99.79it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Loss: 42812.77225971222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 4715/4715 [00:44<00:00, 105.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Loss: 42805.36936187744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 4715/4715 [00:46<00:00, 102.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Loss: 42798.24196052551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 4715/4715 [00:49<00:00, 96.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Loss: 42791.20170021057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 4715/4715 [00:47<00:00, 100.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Loss: 42784.31336784363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 4715/4715 [00:47<00:00, 99.62it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Loss: 42777.625042915344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 4715/4715 [00:47<00:00, 99.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Loss: 42771.04719829559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 4715/4715 [00:47<00:00, 99.94it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss: 42764.530077934265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 4715/4715 [00:47<00:00, 99.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Loss: 42758.14813899994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 4715/4715 [00:49<00:00, 96.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Loss: 42751.872051239014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 4715/4715 [00:47<00:00, 99.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Loss: 42745.608711242676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 4715/4715 [00:47<00:00, 99.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Loss: 42739.455406188965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 4715/4715 [00:49<00:00, 96.19it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Loss: 42733.34494972229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 4715/4715 [00:47<00:00, 99.41it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Loss: 42727.338163375854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 4715/4715 [00:47<00:00, 99.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Loss: 42721.3763923645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 4715/4715 [00:47<00:00, 100.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Loss: 42715.405791282654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 4715/4715 [00:47<00:00, 99.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Loss: 42709.591044425964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 4715/4715 [00:47<00:00, 99.90it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Loss: 42703.75785636902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 4715/4715 [00:48<00:00, 96.34it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Loss: 42698.00225830078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 4715/4715 [00:47<00:00, 99.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Loss: 42692.288405418396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 4715/4715 [00:47<00:00, 99.81it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Loss: 42686.559891700745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 4715/4715 [00:49<00:00, 95.85it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Loss: 42680.92001914978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 4715/4715 [00:47<00:00, 99.74it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Loss: 42675.32559013367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 4715/4715 [00:47<00:00, 99.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Loss: 42669.71421337128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 4715/4715 [00:47<00:00, 99.80it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Loss: 42664.21455574036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 4715/4715 [00:47<00:00, 99.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Loss: 42658.61896133423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 4715/4715 [00:47<00:00, 99.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Loss: 42653.22127056122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 4715/4715 [00:49<00:00, 95.98it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 42647.771646499634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for context_tensors, target_tensors in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        \n",
    "        context_tensors = context_tensors.to(device)\n",
    "        target_tensors = target_tensors.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(context_tensors)\n",
    "        loss = loss_fn(outputs, target_tensors)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    epoch_losses.append(total_loss)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analys about the DataLoader: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Due to the large volume of data, I opted for the DataLoader to efficiently manage the training iterator. When I increase the BATCH_SIZE, the volume of data processed in each batch also increases. Consequently, to process the entire dataset, the number of batches required decreases.\n",
    "- By using DataLoader, I can segment the data into multiple batches. By adjusting the BATCH_SIZE, I can optimize the efficiency of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Model of CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epoch_losses)\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Implement Skipgram:\n",
    "- Create the architecture for Skipgram, which is essentially the inverse of CBOW.\n",
    "- Generate training samples. For each word in the dataset, create pairs with n surrounding words.\n",
    "- Train the model using a suitable optimizer and loss function.\n",
    "- Extract word embeddings for the vocabulary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training samples. For each word in the dataset, create pairs with n surrounding words.\n",
    "def generate_skipgram_pairs(corpus, window_size, vocab_set):\n",
    "    data = []\n",
    "\n",
    "    for i, target_word in enumerate(corpus):  \n",
    "        \n",
    "        # Check if the current target word is in the vocabulary\n",
    "        if target_word not in vocab_set:\n",
    "            continue\n",
    "        \n",
    "        # Define the starting and ending positions for the window\n",
    "        start_index = max(0, i - window_size)\n",
    "        end_index = min(len(corpus), i + window_size + 1)\n",
    "\n",
    "        context = []\n",
    "\n",
    "        # Iterate within the window range and collect context words\n",
    "        for j in range(start_index, end_index):\n",
    "            # Ensure we are not collecting the target word and the word collected is in the vocabulary\n",
    "            if j != i and corpus[j] in vocab_set:\n",
    "                context.append(corpus[j])\n",
    "        \n",
    "        # Only add to the data list if there are context words\n",
    "        if context:  \n",
    "            data.append((context, target_word))\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair 1:\n",
      "Context: ['originated', 'working']\n",
      "Target: anarchism\n",
      "----------------------\n",
      "Pair 2:\n",
      "Context: ['anarchism', 'working']\n",
      "Target: originated\n",
      "----------------------\n",
      "Pair 3:\n",
      "Context: ['anarchism', 'originated']\n",
      "Target: working\n",
      "----------------------\n",
      "Pair 4:\n",
      "Context: ['organization']\n",
      "Target: used\n",
      "----------------------\n",
      "Pair 5:\n",
      "Context: ['used', 'positive', 'label']\n",
      "Target: organization\n",
      "----------------------\n",
      "Pair 6:\n",
      "Context: ['organization', 'label', 'anarchists']\n",
      "Target: positive\n",
      "----------------------\n",
      "Pair 7:\n",
      "Context: ['organization', 'positive', 'anarchists', 'anarchism']\n",
      "Target: label\n",
      "----------------------\n",
      "Pair 8:\n",
      "Context: ['positive', 'label', 'anarchism']\n",
      "Target: anarchists\n",
      "----------------------\n",
      "Pair 9:\n",
      "Context: ['label', 'anarchists', 'chief']\n",
      "Target: anarchism\n",
      "----------------------\n",
      "Pair 10:\n",
      "Context: ['anarchism', 'anarchism', 'belief']\n",
      "Target: chief\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "# Check the generate function for skipgram\n",
    "target_pairs = generate_skipgram_pairs(subsamped_lines[:30000], 2, top_freq_words)\n",
    "\n",
    "# print head 10\n",
    "# Use target to predict contex\n",
    "for i, (context, target) in enumerate(target_pairs[:10]):\n",
    "    print(f\"Pair {i+1}:\")\n",
    "    print(\"Context:\", context)\n",
    "    print(\"Target:\", target)\n",
    "    print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the architecture for Skipgram\n",
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super(SkipGram, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.linear = nn.Linear(embed_dim, vocab_size)\n",
    "        self.activation = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "    def forward(self, context_word):\n",
    "        embeds = self.embeddings(context_word)\n",
    "        out = self.linear(embeds)\n",
    "        out = self.activation(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipgram dataset\n",
    "class SkipGramDataset(Dataset):\n",
    "    def __init__(self, data, word2idx):\n",
    "        self.data = data\n",
    "        self.word2idx = word2idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "    \n",
    "        context, target = self.data[idx]\n",
    "        context_index = self.word2idx[context]\n",
    "        target_index = self.word2idx[target]\n",
    "\n",
    "        return torch.tensor(context_index, dtype=torch.long), torch.tensor(target_index, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "embedding_dim = 100\n",
    "learning_rate = 0.01\n",
    "epochs = 50\n",
    "window_size = 2\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "# Preparing data\n",
    "vocab = set(top_freq_words)\n",
    "vocab.add(\"<NEU>\")\n",
    "word2idx = {word: i for i, word in enumerate(vocab)}\n",
    "idx2word = {i: word for word, i in word2idx.items()}\n",
    "\n",
    "# Preprocess data\n",
    "training_data = generate_skipgram_pairs(subsamped_lines, window_size, vocab)\n",
    "skipgram_dataset = SkipGramDataset(training_data, word2idx)\n",
    "max_context_size = max([len(context) for context, _ in training_data])\n",
    "\n",
    "skipgram_loader = DataLoader(skipgram_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# SkipGram Model, Optimizer, Loss Function\n",
    "model = SkipGram(len(vocab), embedding_dim).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "# List to store losses\n",
    "epoch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/4543 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "each element in list of batch should be of equal size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\GithubRepo\\NaturalLanguageProcessing_Intro\\as3\\CS6120_NLP_Assignment_3.ipynb Cell 33\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GithubRepo/NaturalLanguageProcessing_Intro/as3/CS6120_NLP_Assignment_3.ipynb#X53sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GithubRepo/NaturalLanguageProcessing_Intro/as3/CS6120_NLP_Assignment_3.ipynb#X53sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     total_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/GithubRepo/NaturalLanguageProcessing_Intro/as3/CS6120_NLP_Assignment_3.ipynb#X53sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m context_tensors, target_tensors \u001b[39min\u001b[39;00m tqdm(skipgram_loader, desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GithubRepo/NaturalLanguageProcessing_Intro/as3/CS6120_NLP_Assignment_3.ipynb#X53sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         context_tensors \u001b[39m=\u001b[39m context_tensors\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GithubRepo/NaturalLanguageProcessing_Intro/as3/CS6120_NLP_Assignment_3.ipynb#X53sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         target_tensors \u001b[39m=\u001b[39m target_tensors\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\Andy Cui\\.conda\\envs\\nlp\\lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Andy Cui\\.conda\\envs\\nlp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Andy Cui\\.conda\\envs\\nlp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Andy Cui\\.conda\\envs\\nlp\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\Andy Cui\\.conda\\envs\\nlp\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[1;32mc:\\Users\\Andy Cui\\.conda\\envs\\nlp\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:138\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    136\u001b[0m elem_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mnext\u001b[39m(it))\n\u001b[0;32m    137\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mlen\u001b[39m(elem) \u001b[39m==\u001b[39m elem_size \u001b[39mfor\u001b[39;00m elem \u001b[39min\u001b[39;00m it):\n\u001b[1;32m--> 138\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39meach element in list of batch should be of equal size\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n",
      "\u001b[1;31mRuntimeError\u001b[0m: each element in list of batch should be of equal size"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for context_tensors, target_tensors in tqdm(skipgram_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        \n",
    "        context_tensors = context_tensors.to(device)\n",
    "        target_tensors = target_tensors.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(context_tensors)\n",
    "        loss = loss_fn(outputs, target_tensors)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    epoch_losses.append(total_loss)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Evaluation:\n",
    "- Implement a simple cosine similarity function to measure similarity between word pairs.\n",
    "- Test the similarity of a few pairs of words (e.g., king & queen, man & woman, Paris & France).\n",
    "- Visualize embeddings of some selected words using t-SNE or PCA.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Report:\n",
    "- Provide a brief introduction to word embeddings, Skipgram, and CBOW.\n",
    "- Discuss the architecture of the models.\n",
    "- Describe the dataset and pre-processing steps.\n",
    "- Present results from the evaluation step.\n",
    "- Discuss challenges faced during implementation and potential improvements.\n",
    "- Conclude with insights and potential applications of the implemented models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
